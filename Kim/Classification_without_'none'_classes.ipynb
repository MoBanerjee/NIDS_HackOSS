{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e77a53d-bc85-4c1c-b4bb-84056a4620cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b82ab9-ced4-45b6-9638-1f36f5385122",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_csv(\"./FinalDatasets/TotalDataset_Engineered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ffc00c-85a7-4002-b53f-98727a419166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date first seen</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Proto</th>\n",
       "      <th>Src IP Addr</th>\n",
       "      <th>Src Pt</th>\n",
       "      <th>Dst IP Addr</th>\n",
       "      <th>Dst Pt</th>\n",
       "      <th>Packets</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>F</th>\n",
       "      <th>class</th>\n",
       "      <th>attackType</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>days</th>\n",
       "      <th>hours</th>\n",
       "      <th>minutes</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-15 00:01:16.632</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445</td>\n",
       "      <td>192.168.220.16</td>\n",
       "      <td>58844.0</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-03-15 00:01:16.552</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445</td>\n",
       "      <td>192.168.220.15</td>\n",
       "      <td>48888.0</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-15 00:01:16.551</td>\n",
       "      <td>0.004</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.220.15</td>\n",
       "      <td>48888</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445.0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-15 00:01:16.631</td>\n",
       "      <td>0.004</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.220.16</td>\n",
       "      <td>58844</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445.0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-03-15 00:01:17.432</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>192.168.220.9</td>\n",
       "      <td>37884</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>445.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          Date first seen  Duration Proto     Src IP Addr  \\\n",
       "0           0  2017-03-15 00:01:16.632     0.000   TCP   192.168.100.5   \n",
       "1           1  2017-03-15 00:01:16.552     0.000   TCP   192.168.100.5   \n",
       "2           2  2017-03-15 00:01:16.551     0.004   TCP  192.168.220.15   \n",
       "3           3  2017-03-15 00:01:16.631     0.004   TCP  192.168.220.16   \n",
       "4           4  2017-03-15 00:01:17.432     0.000   TCP   192.168.220.9   \n",
       "\n",
       "   Src Pt     Dst IP Addr   Dst Pt  Packets  Bytes  ...  S  F   class  \\\n",
       "0     445  192.168.220.16  58844.0        1    108  ...  0  0  normal   \n",
       "1     445  192.168.220.15  48888.0        1    108  ...  0  0  normal   \n",
       "2   48888   192.168.100.5    445.0        2    174  ...  0  0  normal   \n",
       "3   58844   192.168.100.5    445.0        2    174  ...  0  0  normal   \n",
       "4   37884   192.168.100.5    445.0        1     66  ...  0  0  normal   \n",
       "\n",
       "   attackType  year  month days hours  minutes  seconds  \n",
       "0        none  2017      3   15     0        1   16.632  \n",
       "1        none  2017      3   15     0        1   16.552  \n",
       "2        none  2017      3   15     0        1   16.551  \n",
       "3        none  2017      3   15     0        1   16.631  \n",
       "4        none  2017      3   15     0        1   17.432  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b57e82-db7e-4f8b-ab62-2522abd0f996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39643009 entries, 0 to 39643008\n",
      "Data columns (total 24 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Unnamed: 0       int64  \n",
      " 1   Date first seen  object \n",
      " 2   Duration         float64\n",
      " 3   Proto            object \n",
      " 4   Src IP Addr      object \n",
      " 5   Src Pt           int64  \n",
      " 6   Dst IP Addr      object \n",
      " 7   Dst Pt           float64\n",
      " 8   Packets          int64  \n",
      " 9   Bytes            int64  \n",
      " 10  U                int64  \n",
      " 11  A                int64  \n",
      " 12  P                int64  \n",
      " 13  R                int64  \n",
      " 14  S                int64  \n",
      " 15  F                int64  \n",
      " 16  class            object \n",
      " 17  attackType       object \n",
      " 18  year             int64  \n",
      " 19  month            int64  \n",
      " 20  days             int64  \n",
      " 21  hours            int64  \n",
      " 22  minutes          int64  \n",
      " 23  seconds          float64\n",
      "dtypes: float64(3), int64(15), object(6)\n",
      "memory usage: 7.1+ GB\n"
     ]
    }
   ],
   "source": [
    "total_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab786002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing none type attackType\n",
    "\n",
    "total_data = total_data[total_data.attackType != \"none\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56970df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5939551 entries, 14 to 39643001\n",
      "Data columns (total 24 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Unnamed: 0       int64  \n",
      " 1   Date first seen  object \n",
      " 2   Duration         float64\n",
      " 3   Proto            object \n",
      " 4   Src IP Addr      object \n",
      " 5   Src Pt           int64  \n",
      " 6   Dst IP Addr      object \n",
      " 7   Dst Pt           float64\n",
      " 8   Packets          int64  \n",
      " 9   Bytes            int64  \n",
      " 10  U                int64  \n",
      " 11  A                int64  \n",
      " 12  P                int64  \n",
      " 13  R                int64  \n",
      " 14  S                int64  \n",
      " 15  F                int64  \n",
      " 16  class            object \n",
      " 17  attackType       object \n",
      " 18  year             int64  \n",
      " 19  month            int64  \n",
      " 20  days             int64  \n",
      " 21  hours            int64  \n",
      " 22  minutes          int64  \n",
      " 23  seconds          float64\n",
      "dtypes: float64(3), int64(15), object(6)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "total_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721eb906-6853-4744-94dd-be65d78eda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Proto', 'Src IP Addr', 'Dst IP Addr']:\n",
    "    total_data[col] = total_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a65b2-c432-48af-b6d1-bfb206f6f5bd",
   "metadata": {},
   "source": [
    "#### One concern I have with some of these features is that the featuers with IP Addresses I believe should be removed. \n",
    "#### Because what happens if we test on new data and that data contains an IP address that the model has never seen before and we are feeding the IP Address as a categorical column. \n",
    "#### So either we modify the data/model to take in the IP Address as a varying non-categorical value OR we drop the IP Addresses feature totally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af3a07-858b-4944-82a7-93b34463fdb2",
   "metadata": {},
   "source": [
    "# Prepping for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03786d8-4fe3-418c-87e2-04ec0819d165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Duration', 'Src Pt', 'Dst Pt', 'Packets', 'Bytes', 'U', 'A', 'P', 'R', 'S', 'F', 'year', 'month', 'days', 'hours', 'minutes', 'seconds']\n"
     ]
    }
   ],
   "source": [
    "features = list(total_data.columns)\n",
    "features.remove(\"Unnamed: 0\")\n",
    "features.remove(\"Date first seen\")\n",
    "features.remove(\"class\")\n",
    "features.remove(\"attackType\")\n",
    "\n",
    "# Dropping these columns for now\n",
    "features.remove('Proto')\n",
    "features.remove('Src IP Addr')\n",
    "features.remove('Dst IP Addr')\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c01ff01a-f974-4351-a308-22dc490ffb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Label Encoding our target variable column\n",
    "le = LabelEncoder()\n",
    "total_data['attackType'] = le.fit_transform(total_data['attackType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044b0fc1-505d-4fc6-8a08-d92e6740439f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blasterWorm': 0, 'bruteForce': 1, 'dos': 2, 'fragmentation': 3, 'httpFlood': 4, 'icmpFlood': 5, 'landAttack': 6, 'pingScan': 7, 'portScan': 8, 'reaperWorm': 9, 'redWorm': 10, 'scanning': 11, 'smurf': 12, 'spam': 13, 'synFlood': 14, 'udpFlood': 15}\n"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94820df9-1f3a-40e5-9cec-5e713a9b3c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"attackType\" # This is going to be a multiclass classification task "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7111df-180d-4735-984e-822e6432155d",
   "metadata": {},
   "source": [
    "#### Since I will be using CatBoostClassifier first, we won't need to undergo any feature normalization of sorts as it is a tree based model.\n",
    "#### However, there are some articles and papers out there mentioning since this is a gradient boosting model, we would still need to normalize data. For now, I will just proceed on but would be a good attempt to try and normalize the data in the future and observe if there are any meaningful changes to the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c29c0f-7156-4cc9-9786-1e1c798f4577",
   "metadata": {},
   "source": [
    "# Splitting data up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b895c84c-ac77-45ca-82f1-29beb12e5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split():\n",
    "    \n",
    "    def __init__(self, num = 5):  # num refers to the number of datasets you wanna split the original total dataset into\n",
    "        self.total_data = total_data\n",
    "        self.target = le.classes_.tolist()\n",
    "        self._0 = []\n",
    "        self._1 = []\n",
    "        self._2 = []\n",
    "        self._3 = []\n",
    "        self._4 = []\n",
    "        self._5 = []\n",
    "        self._6 = []\n",
    "        self._7 = []\n",
    "        self._8 = []\n",
    "        self._9 = []\n",
    "        self._10 = []\n",
    "        self._11 = []\n",
    "        self._12 = []\n",
    "        self._13 = []\n",
    "        self._14 = []\n",
    "        self._15 = []\n",
    "        self._16 = []\n",
    "        self.cv = num\n",
    "\n",
    "    def generate(self):\n",
    "        self._split()\n",
    "\n",
    "        res = []\n",
    "        \n",
    "        for i in tqdm(range(self.cv)):\n",
    "            if i != self.cv-1:\n",
    "                tmp = self._0[i*(len(self._0)//self.cv):(i+1)*(len(self._0)//self.cv)] + self._1[i*(len(self._1)//self.cv):(i+1)*(len(self._1)//self.cv)] + self._2[i*(len(self._2)//self.cv):(i+1)*(len(self._2)//self.cv)] + self._3[i*(len(self._3)//self.cv):(i+1)*(len(self._3)//self.cv)] + self._4[i*(len(self._4)//self.cv):(i+1)*(len(self._4)//self.cv)] + self._5[i*(len(self._5)//self.cv):(i+1)*(len(self._5)//self.cv)] + self._6[i*(len(self._6)//self.cv):(i+1)*(len(self._6)//self.cv)] + self._7[i*(len(self._7)//self.cv):(i+1)*(len(self._7)//self.cv)] + self._8[i*(len(self._8)//self.cv):(i+1)*(len(self._8)//self.cv)] + self._9[i*(len(self._9)//self.cv):(i+1)*(len(self._9)//self.cv)] + self._10[i*(len(self._10)//self.cv):(i+1)*(len(self._10)//self.cv)] + self._11[i*(len(self._11)//self.cv):(i+1)*(len(self._11)//self.cv)] + self._12[i*(len(self._12)//self.cv):(i+1)*(len(self._12)//self.cv)] + self._13[i*(len(self._13)//self.cv):(i+1)*(len(self._13)//self.cv)] + self._14[i*(len(self._14)//self.cv):(i+1)*(len(self._14)//self.cv)] + self._15[i*(len(self._15)//self.cv):(i+1)*(len(self._15)//self.cv)] + self._16[i*(len(self._16)//self.cv):(i+1)*(len(self._16)//self.cv)]\n",
    "            elif i == self.cv-1:\n",
    "                tmp = self._0[i*(len(self._0)//self.cv):-1] + self._1[i*(len(self._1)//self.cv):-1] + self._2[i*(len(self._2)//self.cv):-1] + self._3[i*(len(self._3)//self.cv):-1] + self._4[i*(len(self._4)//self.cv):-1] + self._5[i*(len(self._5)//self.cv):-1] + self._6[i*(len(self._6)//self.cv):-1] + self._7[i*(len(self._7)//self.cv):-1] + self._8[i*(len(self._8)//self.cv):-1] + self._9[i*(len(self._9)//self.cv):-1] + self._10[i*(len(self._10)//self.cv):-1] + self._11[i*(len(self._11)//self.cv):-1] + self._12[i*(len(self._12)//self.cv):-1] + self._13[i*(len(self._13)//self.cv):-1] + self._14[i*(len(self._14)//self.cv):-1] + self._15[i*(len(self._15)//self.cv):-1] + self._16[i*(len(self._16)//self.cv):-1]\n",
    "            res.append(tmp)\n",
    "\n",
    "        return res # Returns arrays of indices\n",
    "        \n",
    "    def _split(self):\n",
    "        length = len(self.total_data)\n",
    "        print(\"Splitting...\")\n",
    "        for i in tqdm(range(length)):\n",
    "            ttype = self.total_data.iloc[i].attackType\n",
    "            match ttype:\n",
    "                case 0:\n",
    "                    self._0.append(i)\n",
    "                case 1:\n",
    "                    self._1.append(i)\n",
    "                case 2:\n",
    "                    self._2.append(i)\n",
    "                case 3:\n",
    "                    self._3.append(i)\n",
    "                case 4:\n",
    "                    self._4.append(i)\n",
    "                case 5: \n",
    "                    self._5.append(i)\n",
    "                case 6:\n",
    "                    self._6.append(i)\n",
    "                case 7:\n",
    "                    self._7.append(i)\n",
    "                case 8:\n",
    "                    self._8.append(i)\n",
    "                case 9:\n",
    "                    self._9.append(i)\n",
    "                case 10:\n",
    "                    self._10.append(i)\n",
    "                case 11:\n",
    "                    self._11.append(i)\n",
    "                case 12:\n",
    "                    self._12.append(i)\n",
    "                case 13:\n",
    "                    self._13.append(i)\n",
    "                case 14:\n",
    "                    self._14.append(i)\n",
    "                case 15:\n",
    "                    self._15.append(i)\n",
    "                case 16:\n",
    "                    self._16.append(i)\n",
    "\n",
    "        print(\"Splitting done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaed510e-8e9d-43fb-82f2-300f3e8184b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5939551/5939551 [03:01<00:00, 32663.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 28.33it/s]\n"
     ]
    }
   ],
   "source": [
    "subset_count = 5\n",
    "split = Split(num = subset_count) # num refers to the number of datasets you wanna split the original total dataset into\n",
    "split_data = split.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c358938-bb58-44f8-ac8d-ead2cdcab6e7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4ab0f6e-a7f7-45b5-bd8f-2bbde84d6813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Take the models from here and insert it below\n",
    "\n",
    "xgb = XGBClassifier(objective='multi:softprob',\n",
    "                   enable_categorical=True)\n",
    "\n",
    "cat = CatBoostClassifier(loss_function='MultiClass', # MultiClass, MultiClassOneVsAll\n",
    "                         eval_metric =  'Accuracy', # AUC\n",
    "                         verbose=10,\n",
    "                         depth = 5,\n",
    "                         early_stopping_rounds=10,\n",
    "                         # cat_features=[1, 2, 4]\n",
    "                        )\n",
    "\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bee94b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6d77e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_data = split_data[0] + split_data[1] + split_data[2] + split_data[3]\n",
    "test_data = split_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ef452b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 1\n",
      "----------------------\n",
      "Training\n",
      "----------------------\n",
      "Learning rate set to 0.127329\n",
      "0:\tlearn: 0.9776758\ttest: 0.9774835\tbest: 0.9774835 (0)\ttotal: 2.3s\tremaining: 38m 19s\n",
      "10:\tlearn: 0.9847252\ttest: 0.9845979\tbest: 0.9846379 (7)\ttotal: 20.1s\tremaining: 30m 11s\n",
      "20:\tlearn: 0.9867629\ttest: 0.9859185\tbest: 0.9859185 (19)\ttotal: 36.7s\tremaining: 28m 32s\n",
      "30:\tlearn: 0.9871178\ttest: 0.9862152\tbest: 0.9862184 (26)\ttotal: 53s\tremaining: 27m 35s\n",
      "40:\tlearn: 0.9874669\ttest: 0.9863373\tbest: 0.9863373 (38)\ttotal: 1m 7s\tremaining: 26m 24s\n",
      "50:\tlearn: 0.9877544\ttest: 0.9863583\tbest: 0.9863583 (50)\ttotal: 1m 21s\tremaining: 25m 17s\n",
      "60:\tlearn: 0.9878789\ttest: 0.9864078\tbest: 0.9864099 (56)\ttotal: 1m 35s\tremaining: 24m 33s\n",
      "70:\tlearn: 0.9879144\ttest: 0.9864352\tbest: 0.9864457 (65)\ttotal: 1m 49s\tremaining: 23m 57s\n",
      "80:\tlearn: 0.9879267\ttest: 0.9864688\tbest: 0.9864836 (77)\ttotal: 2m 4s\tremaining: 23m 27s\n",
      "90:\tlearn: 0.9879559\ttest: 0.9862826\tbest: 0.9865772 (83)\ttotal: 2m 17s\tremaining: 22m 53s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9865772095\n",
      "bestIteration = 83\n",
      "\n",
      "Shrink model to first 84 iterations.\n",
      "Fold - 1 Accuracy: 98.66%\n",
      "----------------------\n",
      "Fold - 2\n",
      "----------------------\n",
      "Training\n",
      "----------------------\n",
      "Learning rate set to 0.127329\n",
      "0:\tlearn: 0.9775008\ttest: 0.9758388\tbest: 0.9758388 (0)\ttotal: 2.38s\tremaining: 39m 38s\n",
      "10:\tlearn: 0.9844016\ttest: 0.9828795\tbest: 0.9829595 (4)\ttotal: 27.9s\tremaining: 41m 46s\n",
      "20:\tlearn: 0.9868697\ttest: 0.9859869\tbest: 0.9859869 (20)\ttotal: 54.3s\tremaining: 42m 10s\n",
      "30:\tlearn: 0.9870610\ttest: 0.9862184\tbest: 0.9862184 (30)\ttotal: 1m 19s\tremaining: 41m 39s\n",
      "40:\tlearn: 0.9873025\ttest: 0.9865141\tbest: 0.9865151 (38)\ttotal: 1m 43s\tremaining: 40m 22s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9865151254\n",
      "bestIteration = 38\n",
      "\n",
      "Shrink model to first 39 iterations.\n",
      "Fold - 2 Accuracy: 98.65%\n",
      "----------------------\n",
      "Fold - 3\n",
      "----------------------\n",
      "Training\n",
      "----------------------\n",
      "Learning rate set to 0.127329\n",
      "0:\tlearn: 0.9737434\ttest: 0.7909702\tbest: 0.7909702 (0)\ttotal: 2.6s\tremaining: 43m 15s\n",
      "10:\tlearn: 0.9849851\ttest: 0.9849420\tbest: 0.9849420 (10)\ttotal: 28.3s\tremaining: 42m 26s\n",
      "20:\tlearn: 0.9869095\ttest: 0.9861310\tbest: 0.9861321 (19)\ttotal: 54.8s\tremaining: 42m 32s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9861320981\n",
      "bestIteration = 19\n",
      "\n",
      "Shrink model to first 20 iterations.\n",
      "Fold - 3 Accuracy: 98.61%\n",
      "----------------------\n",
      "Fold - 4\n",
      "----------------------\n",
      "Training\n",
      "----------------------\n",
      "Learning rate set to 0.127329\n",
      "0:\tlearn: 0.9774777\ttest: 0.9772941\tbest: 0.9772941 (0)\ttotal: 2.51s\tremaining: 41m 49s\n",
      "10:\tlearn: 0.9846431\ttest: 0.9840802\tbest: 0.9840802 (10)\ttotal: 28.4s\tremaining: 42m 36s\n",
      "20:\tlearn: 0.9867114\ttest: 0.9867540\tbest: 0.9867824 (19)\ttotal: 55.5s\tremaining: 43m 9s\n",
      "30:\tlearn: 0.9868876\ttest: 0.9869834\tbest: 0.9870023 (25)\ttotal: 1m 22s\tremaining: 42m 53s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9870023276\n",
      "bestIteration = 25\n",
      "\n",
      "Shrink model to first 26 iterations.\n",
      "Fold - 4 Accuracy: 98.70%\n",
      "----------------------\n",
      "Fold - 5\n",
      "----------------------\n",
      "Training\n",
      "----------------------\n",
      "Learning rate set to 0.127329\n",
      "0:\tlearn: 0.9784363\ttest: 0.9792439\tbest: 0.9792439 (0)\ttotal: 2.67s\tremaining: 44m 31s\n",
      "10:\tlearn: 0.9857317\ttest: 0.9851598\tbest: 0.9851598 (10)\ttotal: 30.9s\tremaining: 46m 17s\n",
      "20:\tlearn: 0.9867040\ttest: 0.9865099\tbest: 0.9865099 (20)\ttotal: 58.8s\tremaining: 45m 42s\n",
      "30:\tlearn: 0.9870478\ttest: 0.9861542\tbest: 0.9865099 (20)\ttotal: 1m 25s\tremaining: 44m 29s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.986509864\n",
      "bestIteration = 20\n",
      "\n",
      "Shrink model to first 21 iterations.\n",
      "Fold - 5 Accuracy: 98.65%\n",
      "----------------------\n",
      "Average accuracy: 98.65%\n"
     ]
    }
   ],
   "source": [
    "X, y = total_data.iloc[train_validation_data][features], total_data.iloc[train_validation_data][target]\n",
    "models = []\n",
    "acc = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold - {i+1}\")\n",
    "    print(\"----------------------\")\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = CatBoostClassifier(loss_function='MultiClass', # MultiClass, MultiClassOneVsAll\n",
    "                         eval_metric =  'Accuracy', # AUC\n",
    "                         verbose=10,\n",
    "                         depth = 5,\n",
    "                         early_stopping_rounds=10,\n",
    "                         # cat_features=[1, 2, 4]\n",
    "                        )\n",
    "    \n",
    "    eval_set = [(X_test, y_test)]\n",
    "    # Training \n",
    "    print(\"Training\")\n",
    "    print(\"----------------------\")\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "    # model.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=\"merror\", eval_set=eval_set, verbose=10)\n",
    "    models.append(model)\n",
    "\n",
    "    # Predict\n",
    "    pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    acc.append(accuracy)\n",
    "\n",
    "    print(\"Fold - {} Accuracy: {:.2f}%\".format(i+1, accuracy*100))\n",
    "    print(\"----------------------\")\n",
    "\n",
    "print(\"Average accuracy: {:.2f}%\".format(np.mean(acc)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f3e536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy is: 98.02%\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "\n",
    "X, y = total_data.iloc[test_data][features], total_data.iloc[test_data][target]\n",
    "\n",
    "acc = []\n",
    "    \n",
    "for model in models:\n",
    "    pred_new = model.predict(X)\n",
    "    accuracy_new = accuracy_score(y, pred_new)\n",
    "    acc.append(accuracy_new)\n",
    "\n",
    "print(\"The average accuracy is: {:.2f}% on the testing dataset\".format(np.mean(acc)*100) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a01aa30e7cb9fc7776677534e11c9ab1eed0bfffb3501a39ef7b976f9557b493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
